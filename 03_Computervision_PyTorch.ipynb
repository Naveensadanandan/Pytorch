{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOLemplBuk/ceX6tJtLAZH3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Naveensadanandan/Pytorch/blob/main/03_Computervision_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMHk8Pkksu9F",
        "outputId": "c54c3db3-6f87-4d8c-f9e4-cb2450db9a17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.3.1+cu121\n",
            "torchvision version: 0.18.1+cu121\n"
          ]
        }
      ],
      "source": [
        "# Import PyTorch\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# Import torchvision\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Import matplotlib for visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check versions\n",
        "# Note: your PyTorch version shouldn't be lower than 1.10.0 and torchvision version shouldn't be lower than 0.11\n",
        "print(f\"PyTorch version: {torch.__version__}\\ntorchvision version: {torchvision.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Data"
      ],
      "metadata": {
        "id": "cWBHJ96Edi3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.FashionMNIST(\n",
        "    root = \"data\",\n",
        "    train = True,\n",
        "    download= True,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=None\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root = \"data\",\n",
        "    train = False,\n",
        "    download= True,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=None\n",
        ")"
      ],
      "metadata": {
        "id": "G_2nQH0nu8wd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e8a7b55-fc2b-4aa8-aa8d-1d10e22e1c21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 15204352/26421880 [00:06<00:02, 4537829.50it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data.targets),len(train_data.data),len(test_data.targets),len(test_data.data)"
      ],
      "metadata": {
        "id": "q8JlUbO6yzaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.classes,train_data.class_to_idx"
      ],
      "metadata": {
        "id": "lHcAc9aW292A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = train_data[10]\n",
        "print(f\"Image shape: {image.shape}\")\n",
        "plt.imshow(image.squeeze())\n",
        "plt.title(label)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1g1w9Ysk3sAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# See classes\n",
        "class_names = train_data.classes\n",
        "class_names"
      ],
      "metadata": {
        "id": "o0A6FTEL42sp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot more images\n",
        "torch.manual_seed(42)\n",
        "fig = plt.figure(figsize=(9, 9))\n",
        "rows, cols = 4, 4\n",
        "for i in range(1, rows * cols + 1):\n",
        "    random_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
        "    img, label = train_data[random_idx]\n",
        "    fig.add_subplot(rows, cols, i)\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "    plt.title(class_names[label])\n",
        "    plt.axis(False);"
      ],
      "metadata": {
        "id": "PZAoDn4i4RJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing Dataloaders"
      ],
      "metadata": {
        "id": "-qoKpq8A4xdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Setup the batch size hyperparameter\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_data_loader = DataLoader(dataset = train_data,\n",
        "                              batch_size = BATCH_SIZE,\n",
        "                              shuffle=True)\n",
        "test_data_loader = DataLoader(dataset = test_data,\n",
        "                              batch_size = BATCH_SIZE,\n",
        "                              shuffle=False)\n",
        "\n",
        "train_data_loader, test_data_loader"
      ],
      "metadata": {
        "id": "vstKCXPCdrew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features_batch, train_label_batch = next(iter(train_data_loader))\n",
        "train_features_batch.shape, train_label_batch.shape"
      ],
      "metadata": {
        "id": "M9fTL9V6fNkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show a sample\n",
        "torch.manual_seed(42)\n",
        "random_idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
        "img, label = train_features_batch[random_idx], train_label_batch[random_idx]\n",
        "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.title(class_names[label])\n",
        "plt.axis(\"Off\");\n",
        "print(f\"Image size: {img.shape}\")\n",
        "print(f\"Label: {label}, label size: {label.shape}\")"
      ],
      "metadata": {
        "id": "H50jOfVdgv8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a Base line model"
      ],
      "metadata": {
        "id": "UtG6iybojSJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch_flatten = nn.Flatten()\n",
        "x = train_features_batch[0]\n",
        "output = torch_flatten(x)\n",
        "\n",
        "print(f\"shape before apllying flatten : {x.shape}\")\n",
        "print(f\"shape after apllying flatten : {output.shape}\")"
      ],
      "metadata": {
        "id": "yq2IT-7HnOx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionMnistModelV0(nn.Module):\n",
        "  def __init__(self,\n",
        "               input : int,\n",
        "               hidden : int,\n",
        "               output : int) -> None:\n",
        "     super().__init__()\n",
        "     self.linear_layer_stack = nn.Sequential(\n",
        "         nn.Flatten(),\n",
        "         nn.Linear(in_features=input, out_features=hidden),\n",
        "         nn.Linear(in_features=hidden, out_features=output)\n",
        "     )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.linear_layer_stack(x)\n",
        "\n",
        "\n",
        "modelV0 = FashionMnistModelV0(input = 28*28,\n",
        "                              hidden = 8,\n",
        "                              output = len(class_names)).to(\"cpu\")\n",
        "\n",
        "modelV0"
      ],
      "metadata": {
        "id": "sAgOZtIjnuma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dummy = torch.rand(size = (1,28,28))\n",
        "modelV0(dummy).shape"
      ],
      "metadata": {
        "id": "6JKsv_Zlpv-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## downloading helper function"
      ],
      "metadata": {
        "id": "75V4SvOfqMvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "# Download helper functions from Learn PyTorch repo (if not already downloaded)\n",
        "if Path(\"helper_functions.py\").is_file():\n",
        "  print(\"helper_functions.py already exists, skipping download\")\n",
        "else:\n",
        "  print(\"Downloading helper_functions.py\")\n",
        "  # Note: you need the \"raw\" GitHub URL for this to work\n",
        "  request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
        "  with open(\"helper_functions.py\", \"wb\") as f:\n",
        "    f.write(request.content)"
      ],
      "metadata": {
        "id": "l79_tAjauZ6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import accuracy_fn\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optmizer = torch.optim.SGD(params = modelV0.parameters(), lr = 0.1)"
      ],
      "metadata": {
        "id": "dqPh95S1uh2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from timeit import default_timer as timer\n",
        "def print_train_time(start: float, end: float, device: torch.device = None):\n",
        "    \"\"\"Prints difference between start and end time.\n",
        "\n",
        "    Args:\n",
        "        start (float): Start time of computation (preferred in timeit format).\n",
        "        end (float): End time of computation.\n",
        "        device ([type], optional): Device that compute is running on. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        float: time between start and end in seconds (higher is longer).\n",
        "    \"\"\"\n",
        "    total_time = end - start\n",
        "    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
        "    return total_time"
      ],
      "metadata": {
        "id": "TIDulikaBbyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "torch.manual_seed(42)\n",
        "train_time_start_on_cpu = timer()\n",
        "epochs = 3\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"epoch : {epoch}\\n..............\")\n",
        "  train_loss = 0\n",
        "  for batch , (X,y) in enumerate(train_data_loader):\n",
        "    modelV0.train()\n",
        "\n",
        "    y_pred = modelV0(X)\n",
        "\n",
        "    loss = loss_fn(y_pred, y)\n",
        "\n",
        "    train_loss += loss\n",
        "\n",
        "    optmizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optmizer.step()\n",
        "\n",
        "    if batch % 400 == 0:\n",
        "            print(f\"Looked at {batch * len(X)}/{len(train_data_loader.dataset)} samples\")\n",
        "  train_loss /= len(train_data_loader)\n",
        "\n",
        "  modelV0.eval()\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    test_loss, test_acc = 0, 0\n",
        "    for (X_test,y_test) in test_data_loader:\n",
        "      test_pred = modelV0(X_test)\n",
        "\n",
        "      test_loss += loss_fn(test_pred, y_test)\n",
        "\n",
        "      test_acc += accuracy_fn(y_true=y_test, y_pred = test_pred.argmax(dim=1))\n",
        "\n",
        "    test_loss /= len(test_data_loader)\n",
        "\n",
        "        # Divide total accuracy by length of test dataloader (per batch)\n",
        "    test_acc /= len(test_data_loader)\n",
        "  ## Print out what's happening\n",
        "    print(f\"\\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\\n\")\n",
        "\n",
        "# Calculate training time\n",
        "train_time_end_on_cpu = timer()\n",
        "total_train_time_model_0 = print_train_time(start=train_time_start_on_cpu,\n",
        "                                           end=train_time_end_on_cpu,\n",
        "                                           device=str(next(modelV0.parameters()).device))\n",
        "\n"
      ],
      "metadata": {
        "id": "ENyvhZTOu3kO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "ssWZKKAYEcPs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}